{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lecture note : \n",
        "binary tree is not same as decision tree (interviewer trick question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyBc6Qb4x8A-"
      },
      "source": [
        "---\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHb7L2cp1AQk"
      },
      "source": [
        "# ðŸ’  **TUTORIAL: Applying Decision Trees on Forest Cover Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU-Zwqkb1FNg"
      },
      "source": [
        "In this tutorial, we'll be extending our conceptual knowledge of decision tree classifiers in an attempt to classify across the Colorado Roosevelt National Forest dataset, available on Kaggle via **[this link](https://www.kaggle.com/datasets/uciml/forest-cover-type-dataset)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTPaFQQZ1A0B"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7VIkwn31T1q"
      },
      "source": [
        "To start, let's get all of our relevant importations and instantiations underway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AkJKSnaetkxs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from scipy.stats import randint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jkgrIh83LNI"
      },
      "source": [
        "Specifically, we'll be making use of the **`DecisionTreeClassifier()`** algorithm available with SciKit-Learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx5aEvMnyAp7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz2rlGUY3SXW"
      },
      "source": [
        "As always, let's first get access to our dataset and take a look at our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o42UMcIltu-y"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"covtype.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwERYeXw3XBi"
      },
      "source": [
        "We can take a look at our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "L6RZ92Mwt4Zj",
        "outputId": "fd6accca-0a4e-4323-d4fc-45625cb18271"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
              "0                                6279  ...            0            0   \n",
              "1                                6225  ...            0            0   \n",
              "2                                6121  ...            0            0   \n",
              "3                                6211  ...            0            0   \n",
              "4                                6172  ...            0            0   \n",
              "\n",
              "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type39  Soil_Type40  Cover_Type  \n",
              "0            0            0           5  \n",
              "1            0            0           5  \n",
              "2            0            0           2  \n",
              "3            0            0           2  \n",
              "4            0            0           5  \n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N90yDkI3tbz"
      },
      "source": [
        "Some datasets - especially ones curated for machine learning analysis - come with informational metadata that can be investigated and accessed via the **`.info()`** method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLcTYEvKt5oK",
        "outputId": "a0e0158e-b5cb-4aa9-d0ac-85b78081964c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 581012 entries, 0 to 581011\n",
            "Data columns (total 55 columns):\n",
            " #   Column                              Non-Null Count   Dtype\n",
            "---  ------                              --------------   -----\n",
            " 0   Elevation                           581012 non-null  int64\n",
            " 1   Aspect                              581012 non-null  int64\n",
            " 2   Slope                               581012 non-null  int64\n",
            " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n",
            " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64\n",
            " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64\n",
            " 6   Hillshade_9am                       581012 non-null  int64\n",
            " 7   Hillshade_Noon                      581012 non-null  int64\n",
            " 8   Hillshade_3pm                       581012 non-null  int64\n",
            " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n",
            " 10  Wilderness_Area1                    581012 non-null  int64\n",
            " 11  Wilderness_Area2                    581012 non-null  int64\n",
            " 12  Wilderness_Area3                    581012 non-null  int64\n",
            " 13  Wilderness_Area4                    581012 non-null  int64\n",
            " 14  Soil_Type1                          581012 non-null  int64\n",
            " 15  Soil_Type2                          581012 non-null  int64\n",
            " 16  Soil_Type3                          581012 non-null  int64\n",
            " 17  Soil_Type4                          581012 non-null  int64\n",
            " 18  Soil_Type5                          581012 non-null  int64\n",
            " 19  Soil_Type6                          581012 non-null  int64\n",
            " 20  Soil_Type7                          581012 non-null  int64\n",
            " 21  Soil_Type8                          581012 non-null  int64\n",
            " 22  Soil_Type9                          581012 non-null  int64\n",
            " 23  Soil_Type10                         581012 non-null  int64\n",
            " 24  Soil_Type11                         581012 non-null  int64\n",
            " 25  Soil_Type12                         581012 non-null  int64\n",
            " 26  Soil_Type13                         581012 non-null  int64\n",
            " 27  Soil_Type14                         581012 non-null  int64\n",
            " 28  Soil_Type15                         581012 non-null  int64\n",
            " 29  Soil_Type16                         581012 non-null  int64\n",
            " 30  Soil_Type17                         581012 non-null  int64\n",
            " 31  Soil_Type18                         581012 non-null  int64\n",
            " 32  Soil_Type19                         581012 non-null  int64\n",
            " 33  Soil_Type20                         581012 non-null  int64\n",
            " 34  Soil_Type21                         581012 non-null  int64\n",
            " 35  Soil_Type22                         581012 non-null  int64\n",
            " 36  Soil_Type23                         581012 non-null  int64\n",
            " 37  Soil_Type24                         581012 non-null  int64\n",
            " 38  Soil_Type25                         581012 non-null  int64\n",
            " 39  Soil_Type26                         581012 non-null  int64\n",
            " 40  Soil_Type27                         581012 non-null  int64\n",
            " 41  Soil_Type28                         581012 non-null  int64\n",
            " 42  Soil_Type29                         581012 non-null  int64\n",
            " 43  Soil_Type30                         581012 non-null  int64\n",
            " 44  Soil_Type31                         581012 non-null  int64\n",
            " 45  Soil_Type32                         581012 non-null  int64\n",
            " 46  Soil_Type33                         581012 non-null  int64\n",
            " 47  Soil_Type34                         581012 non-null  int64\n",
            " 48  Soil_Type35                         581012 non-null  int64\n",
            " 49  Soil_Type36                         581012 non-null  int64\n",
            " 50  Soil_Type37                         581012 non-null  int64\n",
            " 51  Soil_Type38                         581012 non-null  int64\n",
            " 52  Soil_Type39                         581012 non-null  int64\n",
            " 53  Soil_Type40                         581012 non-null  int64\n",
            " 54  Cover_Type                          581012 non-null  int64\n",
            "dtypes: int64(55)\n",
            "memory usage: 243.8 MB\n"
          ]
        }
      ],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGwzdGoJyCcN"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMZUJVmS308B"
      },
      "source": [
        "Just in case, let's also get rid of any ambient null data quickly.\n",
        "\n",
        "Normally, this is a pretty naive way of doing so as this does not take into account any imputation methodologies that could persist signal from null occurrences.\n",
        "\n",
        "For the sake of brevity and simplicity, however, we can simply delete all null occurrences since they're minimal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "THPu_sIzvUO9"
      },
      "outputs": [],
      "source": [
        "# instructor prefer try/pass block to avoid error\n",
        "try:\n",
        "    dataset.dropna(inplace=True)\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lncr5g8XyDVQ"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIxdYiiN4BHI"
      },
      "source": [
        "Now let's start preparing for machine learning analysis.\n",
        "\n",
        "We'll start by segmenting our data into **`X`** and **`y`** segments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QWRe0AOht7M_"
      },
      "outputs": [],
      "source": [
        "# cover type is the primary variable\n",
        "X, y = dataset.drop(\"Cover_Type\", axis=1), dataset[\"Cover_Type\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RZN1TUg4HNn"
      },
      "source": [
        "From there, we can produce training and testing subsets through the use of our trusty module **`train_test_split()`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QM4nkKeUuCRf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1urHwFpyEYl"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uT8ebXk4M93"
      },
      "source": [
        "We're now ready to make use of our decision tree classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HBVaD6dIuviR"
      },
      "outputs": [],
      "source": [
        "classifier = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "56Bl-gxDu5KT",
        "outputId": "cf9480bd-e31e-4d23-a4d7-61ed4a294c57"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LuCZgrfXu8i-"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc3d6Fuevlct",
        "outputId": "cc897cd2-f337-45b6-cd95-455cead09c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.939235647960896"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics.accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI4_OsiK4PLo"
      },
      "source": [
        "~91-93%! Not bad!\n",
        "\n",
        "Let's see how we can improve our classifier function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbeTiG9KyGra"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPC9MhEV4Se9"
      },
      "source": [
        "To start, let's investigate the expressed signal from each of our features in our dataset!\n",
        "\n",
        "(Yes, we can actually do that!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SsFN1jDyHX_",
        "outputId": "e0c5434c-eb50-40d8-a41c-75733fed6418"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3.38056053e-01, 2.65923204e-02, 1.52915210e-02, 6.29788769e-02,\n",
              "       4.34021874e-02, 1.48550349e-01, 3.00303415e-02, 3.27590498e-02,\n",
              "       2.43305915e-02, 1.43563034e-01, 7.49547590e-03, 4.86259583e-03,\n",
              "       1.32954518e-02, 1.48491036e-03, 1.60464750e-04, 1.02193065e-02,\n",
              "       1.99904101e-03, 1.22856195e-02, 6.07180706e-04, 8.69392999e-04,\n",
              "       0.00000000e+00, 3.54712543e-05, 1.09199270e-04, 2.56772344e-03,\n",
              "       1.85888586e-03, 1.18381336e-03, 2.77150856e-03, 1.55697687e-04,\n",
              "       6.59228194e-06, 8.09240075e-04, 1.29252620e-03, 4.60413342e-06,\n",
              "       8.37298240e-04, 3.11574169e-03, 5.29360333e-04, 8.23104319e-03,\n",
              "       9.40269213e-03, 5.29506723e-03, 5.36326816e-05, 3.66794771e-04,\n",
              "       7.89574004e-04, 1.62847299e-04, 7.24501505e-03, 2.90036347e-03,\n",
              "       5.82203604e-03, 1.25197101e-02, 4.75833494e-03, 4.18506227e-04,\n",
              "       8.75320913e-04, 1.98258134e-05, 1.58068047e-04, 2.13254670e-03,\n",
              "       3.44490567e-03, 1.29228928e-03])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.feature_importances_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJkJdYog4bq9"
      },
      "source": [
        "Yikes, that looks a little... uninterpretable.\n",
        "\n",
        "Let's polish this up so it's clearer as to what we're looking at!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Rm4hUnxUyLTK"
      },
      "outputs": [],
      "source": [
        "importances, features = classifier.feature_importances_, list(X)\n",
        "\n",
        "feature_importances = [(features[iteration], importances[iteration]) for iteration in range(len(features))]\n",
        "feature_importances.sort(reverse=True, key=lambda X: X[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zjAjRRXy1-_",
        "outputId": "e77981e0-ee84-43c4-9340-09e7cd2e1e66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Elevation', 0.3380560533007945),\n",
              " ('Horizontal_Distance_To_Roadways', 0.14855034854123647),\n",
              " ('Horizontal_Distance_To_Fire_Points', 0.14356303441811372),\n",
              " ('Horizontal_Distance_To_Hydrology', 0.06297887694495703),\n",
              " ('Vertical_Distance_To_Hydrology', 0.04340218741401295),\n",
              " ('Hillshade_Noon', 0.03275904977754823),\n",
              " ('Hillshade_9am', 0.030030341458491094),\n",
              " ('Aspect', 0.02659232036875537),\n",
              " ('Hillshade_3pm', 0.024330591523529965),\n",
              " ('Slope', 0.015291520954420157),\n",
              " ('Wilderness_Area3', 0.013295451751083013),\n",
              " ('Soil_Type32', 0.012519710111139984),\n",
              " ('Soil_Type4', 0.012285619493295707),\n",
              " ('Soil_Type2', 0.010219306520091679),\n",
              " ('Soil_Type23', 0.009402692130896626),\n",
              " ('Soil_Type22', 0.008231043194376944),\n",
              " ('Wilderness_Area1', 0.007495475898651351),\n",
              " ('Soil_Type29', 0.007245015052067079),\n",
              " ('Soil_Type31', 0.005822036044601275),\n",
              " ('Soil_Type24', 0.00529506722761015),\n",
              " ('Wilderness_Area2', 0.004862595833986963),\n",
              " ('Soil_Type33', 0.004758334943520184),\n",
              " ('Soil_Type39', 0.003444905674386879),\n",
              " ('Soil_Type20', 0.0031157416908371683),\n",
              " ('Soil_Type30', 0.002900363471570654),\n",
              " ('Soil_Type13', 0.0027715085637802926),\n",
              " ('Soil_Type10', 0.002567723435144427),\n",
              " ('Soil_Type38', 0.0021325467039624217),\n",
              " ('Soil_Type3', 0.0019990410126256345),\n",
              " ('Soil_Type11', 0.0018588858571748908),\n",
              " ('Wilderness_Area4', 0.0014849103634563894),\n",
              " ('Soil_Type17', 0.0012925262027888317),\n",
              " ('Soil_Type40', 0.0012922892755023417),\n",
              " ('Soil_Type12', 0.0011838133614929557),\n",
              " ('Soil_Type35', 0.0008753209130751454),\n",
              " ('Soil_Type6', 0.0008693929985068963),\n",
              " ('Soil_Type19', 0.0008372982399629467),\n",
              " ('Soil_Type16', 0.0008092400746657179),\n",
              " ('Soil_Type27', 0.0007895740038187862),\n",
              " ('Soil_Type5', 0.0006071807062235627),\n",
              " ('Soil_Type21', 0.0005293603329739197),\n",
              " ('Soil_Type34', 0.00041850622651119583),\n",
              " ('Soil_Type26', 0.0003667947710205785),\n",
              " ('Soil_Type28', 0.0001628472994413632),\n",
              " ('Soil_Type1', 0.00016046474988629033),\n",
              " ('Soil_Type37', 0.00015806804660833753),\n",
              " ('Soil_Type14', 0.00015569768685718473),\n",
              " ('Soil_Type9', 0.00010919926992717818),\n",
              " ('Soil_Type25', 5.363268159210528e-05),\n",
              " ('Soil_Type8', 3.5471254265891084e-05),\n",
              " ('Soil_Type36', 1.9825813404661498e-05),\n",
              " ('Soil_Type15', 6.592281937884755e-06),\n",
              " ('Soil_Type18', 4.6041334169353825e-06),\n",
              " ('Soil_Type7', 0.0)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcFEVFJT4h19"
      },
      "source": [
        "We can also look into our expressed memory/storage per features, taking note of our top 15 features which already express most of our signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thHIcXA4y5Qg",
        "outputId": "76338dc2-d034-47a5-9216-1a9dbf8a063d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Features: 204.51596 Mb\n",
            "Top 10 Features: 40.903192 Mb\n"
          ]
        }
      ],
      "source": [
        "print(\"All Features: {} Mb\".format(X_train.memory_usage(index=True).sum() / 1000000))\n",
        "\n",
        "NUM_FEATURES_TO_PERSIST = 10\n",
        "print(f\"Top {NUM_FEATURES_TO_PERSIST} Features: {X_train[[feature[0] for feature in feature_importances[:NUM_FEATURES_TO_PERSIST]]].memory_usage(index=True).sum() / 1000000} Mb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYo9vGrYzSLw"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHcH84lr48ZA"
      },
      "source": [
        "Let's segment our data by our top 15 expressed signal features to save on memory and reduce training time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HU653HtjzPcK"
      },
      "outputs": [],
      "source": [
        "X_train = X_train[[feature[0] for feature in feature_importances[:NUM_FEATURES_TO_PERSIST]]]\n",
        "X_test = X_test[[feature[0] for feature in feature_importances[:NUM_FEATURES_TO_PERSIST]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HeTgkt-hzdit"
      },
      "outputs": [],
      "source": [
        "subspace_classifier = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "tZMslU6Kzlln",
        "outputId": "460e4ed9-2058-4c09-a02f-a1c0ee49b248"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subspace_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SqOpVicbzo02"
      },
      "outputs": [],
      "source": [
        "y_pred = subspace_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVVUtwF-zsua",
        "outputId": "56f6ebf9-a938-43ba-bc23-db2e891fa85b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9175666721168989"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics.accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZGKGlUF4_0H"
      },
      "source": [
        "Hmm... our accuracy largely remained the same (actually it may have degraded a little bit), but we cut our training time by a third."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlhBh_Vqzy8E"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "THCw9YwCz_5p"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "\t\t 'criterion': ['gini', 'entropy'],\n",
        "\t\t 'max_depth': [10, 20, 30],\n",
        "\t\t 'max_leaf_nodes': [1000, 5000, 10000],\n",
        "\t\t 'min_samples_leaf': [20, 50, 100],\n",
        "\t\t 'min_samples_split': [10, 50, 100]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DZy8ffpd0Eis"
      },
      "outputs": [],
      "source": [
        "tuned_classifier = DecisionTreeClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "P9_0L2dT0JE7"
      },
      "outputs": [],
      "source": [
        "model_tuner = GridSearchCV(tuned_classifier, hyperparameters, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "oZ6T8E200Piv",
        "outputId": "bd222710-5d3d-4620-93f2-9097b09c75a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [10, 20, 30],\n",
              "                         &#x27;max_leaf_nodes&#x27;: [1000, 5000, 10000],\n",
              "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100],\n",
              "                         &#x27;min_samples_split&#x27;: [10, 50, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [10, 20, 30],\n",
              "                         &#x27;max_leaf_nodes&#x27;: [1000, 5000, 10000],\n",
              "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100],\n",
              "                         &#x27;min_samples_split&#x27;: [10, 50, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [10, 20, 30],\n",
              "                         'max_leaf_nodes': [1000, 5000, 10000],\n",
              "                         'min_samples_leaf': [20, 50, 100],\n",
              "                         'min_samples_split': [10, 50, 100]})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_tuner.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "A8oBseNs0WM3",
        "outputId": "f75cccbb-2348-401f-b78c-4f8d5ee05aaf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=30, max_leaf_nodes=10000,\n",
              "                       min_samples_leaf=20, min_samples_split=10,\n",
              "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=30, max_leaf_nodes=10000,\n",
              "                       min_samples_leaf=20, min_samples_split=10,\n",
              "                       random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=30, max_leaf_nodes=10000,\n",
              "                       min_samples_leaf=20, min_samples_split=10,\n",
              "                       random_state=42)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimally_tuned_classifier = model_tuner.best_estimator_\n",
        "\n",
        "optimally_tuned_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jTp7Gq4f0vBC"
      },
      "outputs": [],
      "source": [
        "y_pred = optimally_tuned_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrKAVj3n0m9Q",
        "outputId": "e9bcc4b5-d8de-4509-e2f0-ef740b791905"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8795728165365783"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics.accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Homework : Rise accuracy. Don't go back. do it from here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Feature Engineering\n",
        "# Transform existing ones to improve model performance\n",
        "\n",
        "# 3. Ensemble Methods\n",
        "# Combine predictions from multiple models to improve accuracy\n",
        "\n",
        "# 4. Data Augmentation\n",
        "# Increase the size of the training dataset by adding modified copies of existing data or newly created synthetic data\n",
        "\n",
        "# 5. Cross-Validation\n",
        "# Use cross-validation to ensure the model generalizes well to unseen data\n",
        "\n",
        "# 6. Regularization\n",
        "# Apply techniques like L1 or L2 regularization to prevent overfitting\n",
        "\n",
        "# END: Suggestions to improve accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with optimally tuned Decision Tree: 0.8974208927480357\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Define the expanded hyperparameter grid\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              # Split criteria\n",
        "    'max_depth': [10, 20, 30, None],               # Expanded max depth, including None for no limit\n",
        "    'max_leaf_nodes': [1000, 5000, 10000],         # Maximum number of leaf nodes\n",
        "    'min_samples_leaf': [10, 20, 50, 100]          # Minimum samples required at a leaf node\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "tuned_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters with cross-validation\n",
        "model_tuner = GridSearchCV(tuned_classifier, hyperparameters, cv=5)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the best estimator from the grid search\n",
        "optimally_tuned_classifier = model_tuner.best_estimator_\n",
        "\n",
        "# Predict on the test data using the best model\n",
        "y_pred = optimally_tuned_classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy score\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with optimally tuned Decision Tree:\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Decision Tree Classifier Accuracy: 0.8846415324905553\n"
          ]
        }
      ],
      "source": [
        "# Randomized Search\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# Define hyperparameter space\n",
        "param_dist = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(), \n",
        "                                   param_distributions=param_dist, \n",
        "                                   n_iter=20, # set the number of iterations\n",
        "                                   cv=5, \n",
        "                                   n_jobs=-1, \n",
        "                                   verbose=0, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting and tuning\n",
        "random_search.fit(X_train, y_train)\n",
        "best_dt_classifier = random_search.best_estimator_\n",
        "\n",
        "# Predict and evaluate with the best estimator\n",
        "y_pred_dt_best = best_dt_classifier.predict(X_test)\n",
        "accuracy_dt_best = metrics.accuracy_score(y_test, y_pred_dt_best)\n",
        "\n",
        "print(\"Best Decision Tree Classifier Accuracy:\", accuracy_dt_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/Cohort_Env/lib/python3.8/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Decision Tree Classifier Accuracy: 0.8969303718492638\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# Hyperparameter space (updated)\n",
        "param_dist = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [10, 20, 30, 40, None],  # max_depth increased\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(), \n",
        "                                   param_distributions=param_dist, \n",
        "                                   n_iter=30,  # increased the number of iterations\n",
        "                                   cv=5, \n",
        "                                   n_jobs=-1, \n",
        "                                   verbose=0, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting and tuning\n",
        "random_search.fit(X_train, y_train)\n",
        "best_dt_classifier = random_search.best_estimator_\n",
        "\n",
        "# Predict and evaluate with the best estimator\n",
        "y_pred_dt_best = best_dt_classifier.predict(X_test)\n",
        "accuracy_dt_best = metrics.accuracy_score(y_test, y_pred_dt_best)\n",
        "\n",
        "print(\"Best Decision Tree Classifier Accuracy:\", accuracy_dt_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with PCA-transformed features: 0.8845296593031161\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=10)  # Selects 10 components (adjustable based on data and variance)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Step 2: Define the hyperparameter grid\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              \n",
        "    'max_depth': [10, 20, 30, None],               \n",
        "    'max_leaf_nodes': [1000, 5000, 10000],         \n",
        "    'min_samples_leaf': [10, 20, 50, 100]          \n",
        "}\n",
        "\n",
        "# Step 3: Initialize and tune the Decision Tree model with PCA-transformed data\n",
        "tuned_classifier = DecisionTreeClassifier(random_state=42)\n",
        "model_tuner = GridSearchCV(tuned_classifier, hyperparameters, cv=5)\n",
        "model_tuner.fit(X_train_pca, y_train)\n",
        "\n",
        "# Step 4: Predict and evaluate using the best model\n",
        "optimally_tuned_classifier = model_tuner.best_estimator_\n",
        "y_pred = optimally_tuned_classifier.predict(X_test_pca)\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy with PCA-transformed features:\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with PCA and RandomizedSearch: 0.8845296593031161\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=10)  # Selects 10 components (adjust based on data)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Step 2: Define the hyperparameter space (more efficient with RandomizedSearch)\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              \n",
        "    'max_depth': [10, 20, 30, None],               \n",
        "    'max_leaf_nodes': [1000, 5000, 10000],         \n",
        "    'min_samples_leaf': [10, 20, 50, 100]          \n",
        "}\n",
        "\n",
        "# Step 3: Use RandomizedSearchCV for faster tuning with fewer parameter combinations\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
        "                                   param_distributions=hyperparameters, \n",
        "                                   n_iter=20, # Limit the number of random combinations\n",
        "                                   cv=5, \n",
        "                                   n_jobs=-1, \n",
        "                                   verbose=0, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting\n",
        "random_search.fit(X_train_pca, y_train)\n",
        "\n",
        "# Best model with PCA and tuned parameters\n",
        "best_classifier = random_search.best_estimator_\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred = best_classifier.predict(X_test_pca)\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy with PCA and RandomizedSearch:\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with Scaled, PCA-transformed features: 0.8205898298666988\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 2: Apply PCA with valid n_components for dimensionality reduction\n",
        "pca = PCA(n_components=10)  # Set within valid range\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Step 3: Define the hyperparameter space\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              \n",
        "    'max_depth': [10, 20, 30, None],               \n",
        "    'max_leaf_nodes': [1000, 5000, 10000],         \n",
        "    'min_samples_leaf': [10, 20, 50, 100]          \n",
        "}\n",
        "\n",
        "# Step 4: Use RandomizedSearchCV for faster tuning\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
        "                                   param_distributions=hyperparameters, \n",
        "                                   n_iter=20, \n",
        "                                   cv=5, \n",
        "                                   n_jobs=-1, \n",
        "                                   verbose=0, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting\n",
        "random_search.fit(X_train_pca, y_train)\n",
        "\n",
        "# Best model with PCA and tuned parameters\n",
        "best_classifier = random_search.best_estimator_\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred = best_classifier.predict(X_test_pca)\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy with Scaled, PCA-transformed features:\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with Selected Features (f_classif): 0.8974208927480357\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Apply SelectKBest with f_classif for feature selection\n",
        "selector = SelectKBest(score_func=f_classif, k=10)  # Select top 10 features\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Step 2: Define the hyperparameter space\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              \n",
        "    'max_depth': [10, 20, 30, None],               \n",
        "    'max_leaf_nodes': [1000, 5000, 10000],         \n",
        "    'min_samples_leaf': [10, 20, 50, 100]          \n",
        "}\n",
        "\n",
        "# Step 3: Use RandomizedSearchCV for faster tuning\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
        "                                   param_distributions=hyperparameters, \n",
        "                                   n_iter=20, \n",
        "                                   cv=5, \n",
        "                                   n_jobs=-1, \n",
        "                                   verbose=0, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting\n",
        "random_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Best model with selected features and tuned parameters\n",
        "best_classifier = random_search.best_estimator_\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred = best_classifier.predict(X_test_selected)\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy with Selected Features (f_classif):\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with All Features and Enhanced Tuning: 0.9034104110909357\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Apply SelectKBest with all features (since n_features=10)\n",
        "selector = SelectKBest(score_func=f_classif, k='all')  # Select all features\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Step 2: Define an expanded hyperparameter space\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              \n",
        "    'max_depth': [10, 20, 30, 40, None],           # Expanded depth range            \n",
        "    'max_leaf_nodes': [500, 1000, 5000, 10000],    # Expanded leaf node options\n",
        "    'min_samples_leaf': [5, 10, 20, 50, 100]       # Adjusted for more granular options\n",
        "}\n",
        "\n",
        "# Step 3: Use RandomizedSearchCV for faster tuning\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
        "                                   param_distributions=hyperparameters, \n",
        "                                   n_iter=30,     # Increased n_iter to explore more combinations\n",
        "                                   cv=5, \n",
        "                                   n_jobs=-1, \n",
        "                                   verbose=0, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting\n",
        "random_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Best model with all features and tuned parameters\n",
        "best_classifier = random_search.best_estimator_\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred = best_classifier.predict(X_test_selected)\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy with All Features and Enhanced Tuning:\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enhanced Accuracy with MinMax Scaling and Expanded Tuning: 0.9022744679569374\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Apply MinMaxScaler for more refined scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 2: Apply SelectKBest with all features (all features are retained)\n",
        "selector = SelectKBest(score_func=f_classif, k='all')  # Select all features\n",
        "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Step 3: Define an even more expanded hyperparameter space\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              \n",
        "    'max_depth': [10, 20, 30, 40, None],            \n",
        "    'max_leaf_nodes': [500, 1000, 5000, 10000],     \n",
        "    'min_samples_leaf': [5, 10, 20, 50, 100],       \n",
        "    'min_samples_split': [2, 5, 10, 20]             # Added min_samples_split for finer tuning\n",
        "}\n",
        "\n",
        "# Step 4: Use RandomizedSearchCV with more cross-validation folds\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
        "                                   param_distributions=hyperparameters, \n",
        "                                   n_iter=40,         # Increased n_iter for broader search\n",
        "                                   cv=10,             # Increased to 10 folds for stability\n",
        "                                   n_jobs=-1, \n",
        "                                   verbose=0, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting\n",
        "random_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Best model with scaled features and further tuned parameters\n",
        "best_classifier = random_search.best_estimator_\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred = best_classifier.predict(X_test_selected)\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Enhanced Accuracy with MinMax Scaling and Expanded Tuning:\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enhanced Accuracy with MinMax Scaling and Expanded Tuning: 0.7465728079309484\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Apply MinMaxScaler for more refined scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 2: Apply SelectKBest with all features (all features are retained)\n",
        "selector = SelectKBest(score_func=f_classif, k='all')  # Select all features\n",
        "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Step 3: Define an even more expanded hyperparameter space\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              \n",
        "    'max_depth': [10, 20, 30, 40, 50],            \n",
        "    'max_leaf_nodes': [500, 1000, 5000, 10000],     \n",
        "    'min_samples_leaf': [5, 10, 20, 50, 100],       \n",
        "    'min_samples_split': [2, 5, 10, 20]             # Added min_samples_split for finer tuning\n",
        "}\n",
        "\n",
        "# Step 4: Use RandomizedSearchCV with more cross-validation folds\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
        "                                   param_distributions=hyperparameters, \n",
        "                                   n_iter=50,         # Increased n_iter for broader search\n",
        "                                   cv=10,             # Increased to 10 folds for stability\n",
        "                                   n_jobs=-1, \n",
        "                                   verbose=0, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting\n",
        "random_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Best model with scaled features and further tuned parameters\n",
        "best_classifier = random_search.best_estimator_\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred = best_classifier.predict(X_test_selected)\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Enhanced Accuracy with MinMax Scaling and Expanded Tuning:\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIb6D70bU-4G"
      },
      "source": [
        "Model performance has dropped slightly, but this is actually to be expected with the inclusion of cross-validation to ensure that we construct an averaged accuracy score more generalized to the entire dataset and not skewed by minor variation across the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Top 10 Features: ['Elevation', 'Horizontal_Distance_To_Roadways', 'Wilderness_Area1', 'Wilderness_Area4', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type10', 'Soil_Type38', 'Soil_Type39']\n",
            "Accuracy with Top 10 Features: 0.6709809557412459\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Feature Selection with SelectKBest\n",
        "# Select top 10 features based on ANOVA F-value\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Get the selected feature names for clarity (optional)\n",
        "selected_features = [X.columns[i] for i in selector.get_support(indices=True)]\n",
        "print(\"Selected Top 10 Features:\", selected_features)\n",
        "\n",
        "# Step 2: Train/Test Split with Selected Features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, train_size=0.8, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Decision Tree Classifier with Selected Features\n",
        "classifier = DecisionTreeClassifier(random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make Predictions and Calculate Accuracy\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with Top 10 Features:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with SelectKBest and PCA: 0.6761185167336472\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "# Step 1: Feature Selection with SelectKBest\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Step 2: PCA for Dimensionality Reduction (optional)\n",
        "# Let's reduce the selected features to 5 principal components\n",
        "pca = PCA(n_components=5)\n",
        "X_reduced = pca.fit_transform(X_selected)\n",
        "\n",
        "# Step 3: Train/Test Split with Reduced Features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, train_size=0.8, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the Decision Tree Classifier with Reduced Features\n",
        "classifier = DecisionTreeClassifier(random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make Predictions and Calculate Accuracy\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with SelectKBest and PCA:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enhanced Accuracy with Stratified K-Fold and Expanded Tuning: 0.7465728079309484\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Step 1: Apply MinMaxScaler for better feature scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 2: Select all features with SelectKBest for now, or a reduced number if necessary\n",
        "selector = SelectKBest(score_func=f_classif, k='all')  # Keep all features\n",
        "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Step 3: Define an expanded hyperparameter space for better tuning\n",
        "hyperparameters = {\n",
        "    'criterion': ['gini', 'entropy'],              \n",
        "    'max_depth': [10, 20, 30, 40, None],            \n",
        "    'max_leaf_nodes': [500, 1000, 5000, 10000],     \n",
        "    'min_samples_leaf': [5, 10, 20, 50, 100],       \n",
        "    'min_samples_split': [2, 5, 10, 20]             \n",
        "}\n",
        "\n",
        "# Step 4: Use Stratified K-Fold Cross-Validation with RandomizedSearchCV\n",
        "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
        "                                   param_distributions=hyperparameters, \n",
        "                                   n_iter=40,        # Iterations for the randomized search\n",
        "                                   cv=stratified_kfold,  # Use Stratified K-Fold here\n",
        "                                   n_jobs=-1, \n",
        "                                   random_state=42)\n",
        "\n",
        "# Model fitting with cross-validation\n",
        "random_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Retrieve the best model from the search\n",
        "best_classifier = random_search.best_estimator_\n",
        "\n",
        "# Prediction and accuracy evaluation\n",
        "y_pred = best_classifier.predict(X_test_selected)\n",
        "accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Enhanced Accuracy with Stratified K-Fold and Expanded Tuning:\", accuracy_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5suND6EO2EJN"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPzUcC-B3Bbk"
      },
      "source": [
        "Finally, we can export any saved decision tree model as a visualization available as a PNG or interactive image file using the **`export_graphviz()`** modular function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "9Bb7FZBy1l_J"
      },
      "outputs": [],
      "source": [
        "labels = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine',\n",
        "     \t'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n",
        "\n",
        "export_graphviz(\n",
        "    subspace_classifier,\n",
        "    out_file=\"forest.dot\",\n",
        "    feature_names=list(X_train),\n",
        "    class_names=labels,\n",
        "    rounded=True,\n",
        "    filled=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "i-VbQRjpVgKo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: dot\n"
          ]
        }
      ],
      "source": [
        "# RUN THIS IN YOUR COMMAND LINE TO GENERATE A PNG!\n",
        "!dot -Tpng forest.dot -o forest.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAWMIqub281S"
      },
      "source": [
        "And that's that!\n",
        "\n",
        "You now know how to utilize a basic CART-designed decision tree algorithm for classification!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwGQLYpXx-JO"
      },
      "source": [
        "---\n",
        "---\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
