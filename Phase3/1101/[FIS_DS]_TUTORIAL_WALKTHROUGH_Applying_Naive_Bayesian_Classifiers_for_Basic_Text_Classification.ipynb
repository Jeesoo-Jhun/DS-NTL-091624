{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c908gmpq8mqv"
      },
      "source": [
        "---\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZVQrffl8pxE"
      },
      "source": [
        "# ðŸ’  **TUTORIAL: Applying Naive Bayesian Classifiers for Basic Text Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5NwOtAF8wUi"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI5juE8T8yDl"
      },
      "source": [
        "This tutorial is designed to showcase NaÃ¯ve Bayes classifiers for text classification purposes â€“Â by the end, you should be comfortable with adding Bayesian classifiers to your machine learning toolkit!\n",
        "\n",
        "Let's start with getting access to all relevant importations and initializations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OegDAt5-7-B1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EgoxMAzLpIi"
      },
      "source": [
        "The main two classifier models we'll be making use of today are the **`GaussianNB()`** and the **`MultinomialNB()`** algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpHsmbj2LOkd"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWNYha0U1oAA"
      },
      "source": [
        "First, let's get access to our dataset.\n",
        "\n",
        "You can access this dataset either via the **[external download link](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)**, the uploaded dataset in the Google Drive, or the shared dataset in the Slack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w4bR149O_AUU"
      },
      "outputs": [],
      "source": [
        "PATH = \"spam.csv\"\n",
        "\n",
        "dataset = pd.read_csv(PATH,\n",
        "                      skiprows=1,\n",
        "                      usecols=[0, 1],\n",
        "                      encoding=\"latin-1\",\n",
        "                      names=[\"target\", \"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "1crKk1AdNN1S",
        "outputId": "accbc041-324a-4b0c-c7f7-987b63897836"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target                                            content\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xNz7Sjv3Bq_"
      },
      "source": [
        "This dataset is comprised of text messages and labels that identify whether the content of the text message is interpretably valuable (`ham`) or contains spam-like and erroneous junk (`spam`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiGTKIG1LPw_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL526Ath3Nof"
      },
      "source": [
        "We'll have to perform some data cleaning and attribution in order to most effectively make use of the dataset for Naive Bayesian modeling.\n",
        "\n",
        "First things first: let's separate the text messages themselves by breaking them up from sentences to cleaned lists-of-words (we'll refer to this as _tokens_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TkoxsBghDTfQ"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    dataset[\"tokens\"] = dataset[\"content\"].str.replace(\"\\W+\", \" \").str.replace(\"\\s+\", \" \").str.strip()\n",
        "    dataset[\"tokens\"] = dataset[\"tokens\"].str.lower()\n",
        "    dataset[\"tokens\"] = dataset[\"tokens\"].str.split()\n",
        "    dataset.drop(columns=[\"content\"], inplace=True)\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CB7afN6MQBjD",
        "outputId": "f0f7f071-18b8-406b-a4a8-e0782ab2a27f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>[go, until, jurong, point,, crazy.., available...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>[ok, lar..., joking, wif, u, oni...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target                                             tokens\n",
              "0    ham  [go, until, jurong, point,, crazy.., available...\n",
              "1    ham               [ok, lar..., joking, wif, u, oni...]\n",
              "2   spam  [free, entry, in, 2, a, wkly, comp, to, win, f..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMO6E6hm3acG"
      },
      "source": [
        "This is performed so we can both clean up any odd symbols and characters across our data as well as so we can more iteratively analyze data without having to worry about modeling constraints like the maximum length of a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSDoc1DwLQnd"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5mmTWRj3jkO"
      },
      "source": [
        "We'll be performing some more advanced data preparation when working with text-based data.\n",
        "\n",
        "In thsi case, we'll be working with a _label encoding algorithm_, which will replace string-like class occurrences within our target label with generatively assigned numerical classes.\n",
        "\n",
        "(We can replace these \"dummy labels\" at any time by using the precise encoding model.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G-WkhhWzEyiO"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9cEcdEvrCwvp"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    dataset[\"target\"] = le.fit_transform(dataset[\"target\"])\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "qkaK46XYR0VA",
        "outputId": "57065d59-b8a7-4294-dc50-ced5a598d882"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[go, until, jurong, point,, crazy.., available...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[ok, lar..., joking, wif, u, oni...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                             tokens\n",
              "0       0  [go, until, jurong, point,, crazy.., available...\n",
              "1       0               [ok, lar..., joking, wif, u, oni...]\n",
              "2       1  [free, entry, in, 2, a, wkly, comp, to, win, f..."
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjsL87dU37WK"
      },
      "source": [
        "Now that our labels are encoded and our data is cleaned, we can move forward for classification purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsjsoCJoLTJw"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjdR5wXi3-di"
      },
      "source": [
        "As always, let's start by segmenting our data into training and testing splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vztr7rrKHfYw"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataset[\"tokens\"],\n",
        "                                                    dataset[\"target\"],\n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrklikGxLgrk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxdGoNGv4CmM"
      },
      "source": [
        "In order to best evaluate our Bayesian classification models, we'll slightly impute our training data using the full range of possible tokens in the data.\n",
        "\n",
        "This is not as important to fully understand as it has to do with reducing error due to the variability of language data; however, if you are interested in natural language processing (NLP) as a future focus, it is recommended to play around with this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CdkYK8E7Ibw4"
      },
      "outputs": [],
      "source": [
        "vocabulary = list(set(X_train.sum()))\n",
        "\n",
        "X_train_vocab = pd.DataFrame(\n",
        "    [[message.count(token) for token in vocabulary] for message in X_train],\n",
        "    columns=vocabulary)\n",
        "X_test_vocab = pd.DataFrame(\n",
        "    [[message.count(token) for token in vocabulary] for message in X_test],\n",
        "    columns=vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "sVmS_n6aSR_3",
        "outputId": "a9300e7d-a78f-46c1-f4b1-d44959740aab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nok</th>\n",
              "      <th>configure</th>\n",
              "      <th>lying.</th>\n",
              "      <th>ansr</th>\n",
              "      <th>june.</th>\n",
              "      <th>hv</th>\n",
              "      <th>me..</th>\n",
              "      <th>lunch?</th>\n",
              "      <th>contract!!</th>\n",
              "      <th>jones!</th>\n",
              "      <th>...</th>\n",
              "      <th>press</th>\n",
              "      <th>play.</th>\n",
              "      <th>yijue...</th>\n",
              "      <th>str</th>\n",
              "      <th>happend?</th>\n",
              "      <th>lips</th>\n",
              "      <th>elaborating</th>\n",
              "      <th>thatÂ‰Ã»Ã·s</th>\n",
              "      <th>2667</th>\n",
              "      <th>hi..i</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4452</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4453</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4454</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4455</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4456</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4457 rows Ã— 11782 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      nok  configure  lying.  ansr  june.  hv  me..  lunch?  contract!!  \\\n",
              "0       0          0       0     0      0   0     0       0           0   \n",
              "1       0          0       0     0      0   0     0       0           0   \n",
              "2       0          0       0     0      0   0     0       0           0   \n",
              "3       0          0       0     0      0   0     0       0           0   \n",
              "4       0          0       0     0      0   0     0       0           0   \n",
              "...   ...        ...     ...   ...    ...  ..   ...     ...         ...   \n",
              "4452    0          0       0     0      0   0     0       0           0   \n",
              "4453    0          0       0     0      0   0     0       0           0   \n",
              "4454    0          0       0     0      0   0     0       0           0   \n",
              "4455    0          0       0     0      0   0     0       0           0   \n",
              "4456    0          0       0     0      0   0     0       0           0   \n",
              "\n",
              "      jones!  ...  press  play.  yijue...  str  happend?  lips  elaborating  \\\n",
              "0          0  ...      0      0         0    0         0     0            0   \n",
              "1          0  ...      0      0         0    0         0     0            0   \n",
              "2          0  ...      0      0         0    0         0     0            0   \n",
              "3          0  ...      0      0         0    0         0     0            0   \n",
              "4          0  ...      0      0         0    0         0     0            0   \n",
              "...      ...  ...    ...    ...       ...  ...       ...   ...          ...   \n",
              "4452       0  ...      0      0         0    0         0     0            0   \n",
              "4453       0  ...      0      0         0    0         0     0            0   \n",
              "4454       0  ...      0      0         0    0         0     0            0   \n",
              "4455       0  ...      0      0         0    0         0     0            0   \n",
              "4456       0  ...      0      0         0    0         0     0            0   \n",
              "\n",
              "      thatÂ‰Ã»Ã·s  2667  hi..i  \n",
              "0            0     0      0  \n",
              "1            0     0      0  \n",
              "2            0     0      0  \n",
              "3            0     0      0  \n",
              "4            0     0      0  \n",
              "...        ...   ...    ...  \n",
              "4452         0     0      0  \n",
              "4453         0     0      0  \n",
              "4454         0     0      0  \n",
              "4455         0     0      0  \n",
              "4456         0     0      0  \n",
              "\n",
              "[4457 rows x 11782 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is the problem with token data?\n",
        "It is high-dimensional. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx6j-5JN4WSj"
      },
      "source": [
        "We're ready to create our models and perform some machine learning analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RqU2vtXKrZP"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjSk4PpA4Zen"
      },
      "source": [
        "As always, we'll design and develop our predictive pipeline here following our four-step process:\n",
        "\n",
        "1. Create our model.\n",
        "2. Fit our model to training data.\n",
        "3. Produce predicted labels using the testing data.\n",
        "4. Assess our model's accuracy by comparing predicted and true labels.\n",
        "\n",
        "In this case, we'll make use of our **Gaussian NaÃ¯ve Bayesian Model** first.\n",
        "\n",
        "This assumes that the distribution of `spam` and `ham` classes is Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "f6ZsjYbCJdll"
      },
      "outputs": [],
      "source": [
        "GaussianNB_Classifier = GaussianNB()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-U5VNkx6D28"
      },
      "source": [
        "Now that our model is created, let's fit it to our modified training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Fq56xsrHJ5au",
        "outputId": "1ac8ad56-6a97-4d64-8d5d-6a488d43891f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GaussianNB_Classifier.fit(X_train_vocab, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uJpA8cP6GMd"
      },
      "source": [
        "Once our model is appropriately fitted, we can go ahead and run some predictions using the similarly modified testing data (without true labels provided)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tEJmOo5qJ5rm"
      },
      "outputs": [],
      "source": [
        "y_pred = GaussianNB_Classifier.predict(X_test_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-PsygMB6Lof"
      },
      "source": [
        "And finally, we can access our accuracy score by comparing true labels to the model-predicted ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1djFyW7jJ5-8",
        "outputId": "e249f02d-33ac-44b9-e23a-04e0e7a9712b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "92.28699551569507"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "100 * accuracy_score(y_true=y_test, y_pred=y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Eld3Wnh6O-0"
      },
      "source": [
        "Not too bad!\n",
        "\n",
        "However, as we level up in predictive analytics, we want to become comfortable with utilizing multiple accuracy methods to ensure our prediction results are truly sound.\n",
        "\n",
        "Standard accuracy tends to not show the importance of failed predictions and errors as strongly as other metrics â€“Â one useful accuracy metric that highlights the impact of false positives/negatives and error rate is the **F1 Score**.\n",
        "\n",
        "Let's go ahead and use that to see how truly accurate our model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuPPH2sFLBwf",
        "outputId": "1b6e108f-ce4d-4477-85d6-1721b9d33051"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "75.56818181818183"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "100 * f1_score(y_true=y_test, y_pred=y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Difference between f1 score and actual accuracy score is huge. There may be wrong with actual.  \n",
        "# And reason for this mismatch could be imbalanced data or mistake with Gaussian Assumption. \n",
        "\n",
        "# Gaussian Naive Bayes assumes features follow a Gaussian (normal) distribution. Word frequencies in text data often don't fit this assumption well. This mismatch can reduce the model's effectiveness in capturing the underlying patterns of the data.#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eCyvXor6gBW"
      },
      "source": [
        "Hmm... not quite as good as we had hoped.\n",
        "\n",
        "It seems our Gaussian expectation may not be as well performant as we expected.\n",
        "\n",
        "That's probably because it's a little _too naÃ¯ve_ to expect two explicit, discrete labels to naturally fall into a normal distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F42J_AOoKsqI"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOYM2E3p6qpp"
      },
      "source": [
        "Instead, let's go ahead and repeat the modeling process but with a better expectation for our distribution.\n",
        "\n",
        "In this case, we'll anticipate our labels to be _binomial_ (a special case of a **multinomial distribution**).\n",
        "\n",
        "We should expect improved accuracy scores after our process is complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zg7ZxtA7KtdJ"
      },
      "outputs": [],
      "source": [
        "MultinomialNB_Classifier = MultinomialNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "PpD7ybQqKtvu",
        "outputId": "ee860802-629c-4b80-a164-ef6b4ed72b56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MultinomialNB_Classifier.fit(X_train_vocab, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XyYa4Y_FKt_6"
      },
      "outputs": [],
      "source": [
        "y_pred = MultinomialNB_Classifier.predict(X_test_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwwB2IpKKuO-",
        "outputId": "889e3aa8-72da-4ee1-c8de-cbfb018cffa4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "98.11659192825111"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "100 * accuracy_score(y_true=y_test, y_pred=y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhhwtQr0LHc6",
        "outputId": "88746ff6-d9d8-4baf-a9af-23a059dee4bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "92.57950530035335"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "100 * f1_score(y_true=y_test, y_pred=y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make F1 Score higher than 92.579"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1 Score: 93.7062937062937 with alpha: 0.1\n"
          ]
        }
      ],
      "source": [
        "# Tune the alpha parameter of MultinomialNB\n",
        "best_f1_score = 0\n",
        "best_alpha = 0\n",
        "for alpha in np.arange(0.1, 1.1, 0.1):\n",
        "    MultinomialNB_Classifier = MultinomialNB(alpha=alpha)\n",
        "    MultinomialNB_Classifier.fit(X_train_vocab, y_train)\n",
        "    y_pred = MultinomialNB_Classifier.predict(X_test_vocab)\n",
        "    f1 = 100 * f1_score(y_true=y_test, y_pred=y_pred)\n",
        "    if f1 > best_f1_score:\n",
        "        best_f1_score = f1\n",
        "        best_alpha = alpha\n",
        "\n",
        "print(f\"Best F1 Score: {best_f1_score} with alpha: {best_alpha}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHoZgppH7DPq"
      },
      "source": [
        "And what do you know!\n",
        "\n",
        "It turns out that with a more appropriate expectation for our labels' distributions, our accuracy is much, much higher!\n",
        "\n",
        "This is why it's so important to understand the relationship between our data and our algorithms _before_ jumping into predictive modeling: it can save us time and a headache in terms of optimizing our results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UfGrg6F8oKN"
      },
      "source": [
        "---\n",
        "---\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
